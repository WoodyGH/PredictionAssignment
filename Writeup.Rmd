---
title: "Prediction Assignment"
author: "WC"
date: "7/28/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Summary
### The goal of this project is to predict the manner ("classe" in the dataset) in which the 6 partcipants did the exercise, using data from accelerometers on the belt, forearm, arm, and dumbell. A variety of training models are tested, including regression trees, random forest, boosting with trees and linear model-based prediction models. Among those tested, the random forest model showed the best accuracy, and thus applied to the test data for classificaton. 

## Step 1: Data download and preparation
### Download from given urls and select 'classe' as response variable, and accelerometer data from belt, forearm, arm and budbell as predictor variables. Then, split the data into training (75%) and testing (25%).

```{r data}
#libraries
library(dplyr)
library(tidyr)
library(ggplot2)
library(caret)
library(rattle)

#data download
org_train_data <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")
org_test_data <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")

#select accelerometer data only.
train_data <- org_train_data %>% select(starts_with("accel_"))
train_data$classe <- org_train_data$classe
test_data <- org_test_data %>% select(starts_with("accel_"))

#split train_data into training and testing
inTrain <- createDataPartition(y=train_data$classe, p=3/4, list=FALSE)
training <- train_data[inTrain,]
testing <- train_data[-inTrain,]
```

## Step 2: Model building
### Build tree regression, random forest, boosting, and linear model-based prediction models.

```{r analysis, cache=TRUE}

#Predicting with trees
tree_mod <- train(classe ~., method="rpart", data=training)
print(tree_mod)
fancyRpartPlot(tree_mod$finalModel)

#Random Forests
rf_mod <- train(classe ~., method="rf", data=training)
print(rf_mod)

#Boosting
gbm_mod <- train(classe ~., method="gbm", data=training, verbose=FALSE)
print(rf_mod)

#Model based prediction
lda_mod <- train(classe ~., method="lda", data=training)
print(lda_mod)

```

## Step 3: Prediction and Accuracy comparison
### Estimate accuracy of each prediction model against testing data and choose the best model.
``` {r prediction & accuracy}
#regression trees
tree_pred <- predict(tree_mod, testing)
table(tree_pred)
tree_acc <- confusionMatrix(tree_pred, as.factor(testing$classe))$overall[1]
print(paste("Regression Trees Accuracy:", tree_acc))

#random forest
rf_pred <- predict(rf_mod, testing)
table(rf_pred)
rf_acc <- confusionMatrix(rf_pred, as.factor(testing$classe))$overall[1]
print(paste("Random Forest Accuracy:", rf_acc))
      
#boosting
gbm_pred <- predict(gbm_mod, testing)
table(gbm_pred)
gbm_acc <- confusionMatrix(gbm_pred, as.factor(testing$classe))$overall[1]
print(paste("Boosting with Trees Accuracy:", gbm_acc))

#model-based
lda_pred <- predict(lda_mod, testing)
table(lda_pred)
lda_acc <- confusionMatrix(lda_pred, as.factor(testing$classe))$overall[1]
print(paste("Linear Model Based Model Accuracy:", lda_acc))

```

## Step 4: Application
### Apply the best model to the new test dataset to predict "classe".
``` {r testing}
new_pred <- predict(rf_mod, test_data)
print(new_pred)
```

## Conclusion
Among the four models tested, the Random Forest model was selected as the best model with the highest accuracy of 0.985522.  Therefore the Random Forest model was applied to the new test dataset with 20 samples, resuting 7 As, 6 Bs, 2 Cs, 2 Ds, and 3 Es.


